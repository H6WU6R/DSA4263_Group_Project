{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import libraries\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnx\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'networkx'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 49,529 emails\n",
      "\\ Columns: ['sender', 'receiver', 'date', 'subject', 'body', 'label', 'urls']\n",
      "\\ Label distribution:\n",
      "label\n",
      "1    28126\n",
      "0    21403\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Spam rate: 56.8%\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"../data/processed/graph_merge.csv\")\n",
    "print(f\"Dataset loaded: {len(df):,} emails\")\n",
    "print(f\"\\ Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\ Label distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "print(f\"\\nSpam rate: {df['label'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning: 49,529 emails\n",
      "\n",
      "============================================================\n",
      " GRAPH STATISTICS:\n",
      "============================================================\n",
      "  Nodes (unique emails):     37,670\n",
      "  Edges (connections):       37,171\n",
      "  Network density:           0.000026\n",
      "  Avg degree:                1.97\n"
     ]
    }
   ],
   "source": [
    "# Clean data\n",
    "df = df.dropna(subset=['sender', 'receiver'])\n",
    "df['sender'] = df['sender'].astype(str).str.strip().str.lower()\n",
    "df['receiver'] = df['receiver'].astype(str).str.strip().str.lower()\n",
    "df = df[(df['sender'] != 'nan') & (df['receiver'] != 'nan')]\n",
    "\n",
    "print(f\"After cleaning: {len(df):,} emails\")\n",
    "\n",
    "# Build directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    sender = row['sender']\n",
    "    receiver = row['receiver']\n",
    "    is_spam = row['label']\n",
    "    \n",
    "    if G.has_edge(sender, receiver):\n",
    "        G[sender][receiver]['weight'] += 1\n",
    "        G[sender][receiver]['spam_count'] += is_spam\n",
    "        G[sender][receiver]['ham_count'] += (1 - is_spam)\n",
    "    else:\n",
    "        G.add_edge(sender, receiver, \n",
    "                   weight=1, \n",
    "                   spam_count=is_spam,\n",
    "                   ham_count=1-is_spam)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\" GRAPH STATISTICS:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Nodes (unique emails):     {G.number_of_nodes():,}\")\n",
    "print(f\"  Edges (connections):       {G.number_of_edges():,}\")\n",
    "print(f\"  Network density:           {nx.density(G):.6f}\")\n",
    "print(f\"  Avg degree:                {sum(dict(G.degree()).values())/G.number_of_nodes():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 sender  out_degree  in_degree  total_sent  \\\n",
      "0                    \"  coinbase   \" <>           1          0           1   \n",
      "1  \" \" <netflix_mails@skybluefoods.net>           1          0           1   \n",
      "2   \" \" <wellsfargo_online@knology.net>           1          0           1   \n",
      "3  \" \" <wellsfargo_online@pflagscv.net>           1          0           1   \n",
      "4       \" amex \" <priemna@leluk.org.ua>           1          0           1   \n",
      "\n",
      "   spam_ratio  reciprocity  pagerank  clustering  degree_centrality  \\\n",
      "0         1.0          0.0  0.000011         0.0           0.000027   \n",
      "1         1.0          0.0  0.000011         0.0           0.000027   \n",
      "2         1.0          0.0  0.000011         0.0           0.000027   \n",
      "3         1.0          0.0  0.000011         0.0           0.000027   \n",
      "4         1.0          0.0  0.000011         0.0           0.000027   \n",
      "\n",
      "   avg_weight  is_spammer  \n",
      "0         1.0           1  \n",
      "1         1.0           1  \n",
      "2         1.0           1  \n",
      "3         1.0           1  \n",
      "4         1.0           1  \n"
     ]
    }
   ],
   "source": [
    "pagerank = nx.pagerank(G, max_iter=50)\n",
    "clustering = nx.clustering(G.to_undirected())\n",
    "out_degrees = dict(G.out_degree())\n",
    "in_degrees = dict(G.in_degree())\n",
    "sender_features = []\n",
    "\n",
    "for sender, group in df.groupby('sender'):\n",
    "    if sender not in G:\n",
    "        continue\n",
    "    \n",
    "    out_deg = out_degrees.get(sender, 0)\n",
    "    if out_deg == 0:\n",
    "        continue\n",
    "\n",
    "    total_sent = len(group)\n",
    "    spam_sent = group['label'].sum()\n",
    "    spam_ratio = spam_sent / total_sent\n",
    "\n",
    "    receivers = list(G.successors(sender))\n",
    "    reciprocity = (\n",
    "        sum(1 for r in receivers if G.has_edge(r, sender)) / len(receivers)\n",
    "        if receivers else 0\n",
    "    )\n",
    "\n",
    "    # avg weight of outgoing edges\n",
    "    avg_weight = (\n",
    "        np.mean([G[sender][r]['weight'] for r in receivers])\n",
    "        if receivers else 0\n",
    "    )\n",
    "\n",
    "    sender_features.append({\n",
    "        'sender': sender,\n",
    "        'out_degree': out_deg,\n",
    "        'in_degree': in_degrees.get(sender, 0),\n",
    "        'total_sent': total_sent,\n",
    "        'spam_ratio': spam_ratio,\n",
    "        'reciprocity': reciprocity,\n",
    "        \n",
    "        # graph features added here\n",
    "        'pagerank': pagerank.get(sender, 0),\n",
    "        'clustering': clustering.get(sender, 0),\n",
    "        'degree_centrality': out_deg / (G.number_of_nodes() - 1),\n",
    "        'avg_weight': avg_weight,\n",
    "\n",
    "        # label\n",
    "        'is_spammer': 1 if spam_ratio > 0.8 else 0\n",
    "    })\n",
    "\n",
    "features_df = pd.DataFrame(sender_features)\n",
    "print(features_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Feature  Spam Mean  Legit Mean  Spam Median  Legit Median  Ratio Interpretation\n",
      " out_degree     1.0414      1.9879          1.0           1.0   0.52   Legit higher\n",
      "  in_degree     0.2702      0.9860          0.0           0.0   0.27   Legit higher\n",
      "reciprocity     0.0082      0.0361          0.0           0.0   0.23   Legit higher\n",
      " total_sent     1.0543      4.5291          1.0           1.0   0.23   Legit higher\n",
      "   pagerank     0.0000      0.0000          0.0           0.0   1.12    Spam higher\n",
      " clustering     0.0002      0.0633          0.0           0.0   0.00   Legit higher\n",
      " avg_weight     1.0088      2.4716          1.0           1.0   0.41   Legit higher\n"
     ]
    }
   ],
   "source": [
    "comparison_features = ['out_degree', 'in_degree', 'reciprocity', 'total_sent', \n",
    "                       'pagerank', 'clustering', 'avg_weight']\n",
    "\n",
    "rows = []\n",
    "for feature in comparison_features:\n",
    "    spam_vals = features_df[features_df['is_spammer'] == 1][feature]\n",
    "    legit_vals = features_df[features_df['is_spammer'] == 0][feature]\n",
    "    \n",
    "    spam_mean = spam_vals.mean()\n",
    "    legit_mean = legit_vals.mean()\n",
    "    spam_med  = spam_vals.median()\n",
    "    legit_med = legit_vals.median()\n",
    "    ratio = spam_mean / legit_mean if legit_mean > 0 else float('inf')\n",
    "    \n",
    "    rows.append([\n",
    "        feature,\n",
    "        round(spam_mean, 4),\n",
    "        round(legit_mean, 4),\n",
    "        round(spam_med, 4),\n",
    "        round(legit_med, 4),\n",
    "        round(ratio, 2),\n",
    "        \"Spam higher\" if ratio > 1 else \"Legit higher\"\n",
    "    ])\n",
    "\n",
    "compare_table = pd.DataFrame(rows, columns=[\n",
    "    \"Feature\", \"Spam Mean\", \"Legit Mean\", \"Spam Median\", \"Legit Median\", \"Ratio\", \"Interpretation\"\n",
    "])\n",
    "\n",
    "print(compare_table.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " COMPUTING ADVANCED GRAPH FEATURES (FAST VERSION)\n",
      "======================================================================\n",
      "\n",
      "[1/4] Computing basic centrality measures...\n",
      "[2/4] Computing closeness and eigenvector centrality...\n",
      "[3/4] Computing HITS (hub/authority scores)...\n",
      "[4/4] Computing additional structural features...\n",
      "   Computing harmonic centrality...\n",
      "   Computing eccentricity...\n",
      "\n",
      "âœ“ All graph features computed!\n",
      "\n",
      "Extracting features for each sender...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing senders: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31398/31398 [00:01<00:00, 16262.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " FEATURE EXTRACTION COMPLETE\n",
      "======================================================================\n",
      "Total features: 36\n",
      "Senders analyzed: 31,398\n",
      "Spammers: 26,671\n",
      "Legitimate: 4,727\n",
      "\n",
      "======================================================================\n",
      " SAMPLE OF EXTRACTED FEATURES\n",
      "======================================================================\n",
      "                                 sender  total_sent  spam_ratio  is_spammer  \\\n",
      "0                    \"  coinbase   \" <>           1         1.0           1   \n",
      "1  \" \" <netflix_mails@skybluefoods.net>           1         1.0           1   \n",
      "2   \" \" <wellsfargo_online@knology.net>           1         1.0           1   \n",
      "3  \" \" <wellsfargo_online@pflagscv.net>           1         1.0           1   \n",
      "4       \" amex \" <priemna@leluk.org.ua>           1         1.0           1   \n",
      "\n",
      "   out_degree  in_degree  total_degree  in_out_ratio  degree_diff  pagerank  \\\n",
      "0           1          0             1           0.0            1  0.000011   \n",
      "1           1          0             1           0.0            1  0.000011   \n",
      "2           1          0             1           0.0            1  0.000011   \n",
      "3           1          0             1           0.0            1  0.000011   \n",
      "4           1          0             1           0.0            1  0.000011   \n",
      "\n",
      "   ...  avg_weight  max_weight  weight_variance  weight_gini  \\\n",
      "0  ...         1.0           1              0.0          0.0   \n",
      "1  ...         1.0           1              0.0          0.0   \n",
      "2  ...         1.0           1              0.0          0.0   \n",
      "3  ...         1.0           1              0.0          0.0   \n",
      "4  ...         1.0           1              0.0          0.0   \n",
      "\n",
      "   avg_neighbor_degree  receiver_diversity  unique_receiver_ratio  \\\n",
      "0                  0.0                 1.0                    1.0   \n",
      "1                  0.0                 1.0                    1.0   \n",
      "2                  0.0                 1.0                    1.0   \n",
      "3                  0.0                 1.0                    1.0   \n",
      "4                  0.0                 1.0                    1.0   \n",
      "\n",
      "   ego_density  ego_nodes  ego_edges  \n",
      "0          0.5          1          1  \n",
      "1          0.5          1          1  \n",
      "2          0.5          1          1  \n",
      "3          0.5          1          1  \n",
      "4          0.5          1          1  \n",
      "\n",
      "[5 rows x 36 columns]\n",
      "\n",
      "======================================================================\n",
      " COMPREHENSIVE FEATURE COMPARISON: SPAMMER vs LEGITIMATE\n",
      "======================================================================\n",
      "              Feature  Spam Mean  Legit Mean  Spam Median  Legit Median  Ratio Interpretation\n",
      "           out_degree   1.041356    1.987942     1.000000      1.000000  0.524   Legit higher\n",
      "            in_degree   0.270219    0.986038     0.000000      0.000000  0.274   Legit higher\n",
      "         in_out_ratio   0.270200    0.295793     0.000000      0.000000  0.913   Legit higher\n",
      "          degree_diff   0.771137    1.001904     1.000000      1.000000  0.770   Legit higher\n",
      "             pagerank   0.000023    0.000021     0.000011      0.000011  1.120    Spam higher\n",
      "            closeness   0.000007    0.000694     0.000000      0.000000  0.010   Legit higher\n",
      "          eigenvector   0.000000    0.001671     0.000000      0.000000  0.000   Legit higher\n",
      "  harmonic_centrality   0.274340   27.663190     0.000000      0.000000  0.010   Legit higher\n",
      "         eccentricity   0.000000    0.093082     0.000000      0.000000  0.000   Legit higher\n",
      "            hub_score   0.000000    0.000212     0.000000      0.000000  0.000   Legit higher\n",
      "      authority_score   0.000000    0.000000     0.000000      0.000000  0.000   Legit higher\n",
      "           clustering   0.000160    0.063267     0.000000      0.000000  0.003   Legit higher\n",
      "            triangles   0.002775    1.466469     0.000000      0.000000  0.002   Legit higher\n",
      "          core_number   1.027521    1.569283     1.000000      1.000000  0.655   Legit higher\n",
      "  neighbor_clustering   0.000046    0.029875     0.000000      0.000000  0.002   Legit higher\n",
      "    neighbor_pagerank   0.009492    0.001351     0.003592      0.000287  7.024    Spam higher\n",
      "          reciprocity   0.000000    0.026782     0.000000      0.000000  0.000   Legit higher\n",
      "         mutual_ratio   0.000000    0.026638     0.000000      0.000000  0.000   Legit higher\n",
      "    num_senders_to_me   0.262045    0.971018     0.000000      0.000000  0.270   Legit higher\n",
      "           avg_weight   0.999848    2.454565     1.000000      1.000000  0.407   Legit higher\n",
      "           max_weight   1.001687    3.077004     1.000000      1.000000  0.326   Legit higher\n",
      "      weight_variance   0.003805    7.408530     0.000000      0.000000  0.001   Legit higher\n",
      "          weight_gini   0.000273    0.041480     0.000000      0.000000  0.007   Legit higher\n",
      "   receiver_diversity   0.991845    0.990571     1.000000      1.000000  1.001    Spam higher\n",
      "unique_receiver_ratio   0.988610    0.762788     1.000000      1.000000  1.296    Spam higher\n",
      "  avg_neighbor_degree   1.014035    1.415615     0.000000      0.000000  0.716   Legit higher\n",
      "          ego_density   0.491450    0.449346     0.500000      0.500000  1.094    Spam higher\n",
      "            ego_nodes   1.033182    1.972922     1.000000      1.000000  0.524   Legit higher\n",
      "\n",
      "======================================================================\n",
      " TOP FEATURES THAT DISTINGUISH SPAMMERS\n",
      "======================================================================\n",
      "\n",
      "Top 10 most discriminative features:\n",
      "            Feature  Spam Mean  Legit Mean  Ratio\n",
      "  neighbor_pagerank   0.009492    0.001351  7.024\n",
      "        eigenvector   0.000000    0.001671  0.000\n",
      "       eccentricity   0.000000    0.093082  0.000\n",
      "          hub_score   0.000000    0.000212  0.000\n",
      "    authority_score   0.000000    0.000000  0.000\n",
      "        reciprocity   0.000000    0.026782  0.000\n",
      "       mutual_ratio   0.000000    0.026638  0.000\n",
      "    weight_variance   0.003805    7.408530  0.001\n",
      "          triangles   0.002775    1.466469  0.002\n",
      "neighbor_clustering   0.000046    0.029875  0.002\n",
      "\n",
      "======================================================================\n",
      " KEY INSIGHTS\n",
      "======================================================================\n",
      "\n",
      "ðŸŽ¯ CENTRALITY DIFFERENCES:\n",
      "   PageRank:     Spam=0.000023 vs Legit=0.000021\n",
      "   Closeness:    Spam=0.000007 vs Legit=0.000694\n",
      "   Eigenvector:  Spam=0.000000 vs Legit=0.001671\n",
      "   Hub score:    Spam=0.000000 vs Legit=0.000212\n",
      "   Authority:    Spam=0.000000 vs Legit=0.000000\n",
      "\n",
      "ðŸ“Š STRUCTURAL DIFFERENCES:\n",
      "   Core number:  Spam=1.03 vs Legit=1.57\n",
      "   Triangles:    Spam=0.00 vs Legit=1.47\n",
      "   Ego density:  Spam=0.4915 vs Legit=0.4493\n",
      "   Clustering:   Spam=0.0002 vs Legit=0.0633\n",
      "\n",
      "ðŸ”— INTERACTION PATTERNS:\n",
      "   In/Out ratio:     Spam=0.2702 vs Legit=0.2958\n",
      "   Reciprocity:      Spam=0.0000 vs Legit=0.0268\n",
      "   Mutual ratio:     Spam=0.0000 vs Legit=0.0266\n",
      "   Receiver div:     Spam=0.9918 vs Legit=0.9906\n",
      "   Weight Gini:      Spam=0.0003 vs Legit=0.0415\n",
      "   Neighbor PR:      Spam=0.009492 vs Legit=0.001351\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" COMPUTING ADVANCED GRAPH FEATURES (FAST VERSION)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Basic graph metrics\n",
    "print(\"\\n[1/4] Computing basic centrality measures...\")\n",
    "pagerank = nx.pagerank(G, max_iter=50)\n",
    "clustering = nx.clustering(G.to_undirected())\n",
    "out_degrees = dict(G.out_degree())\n",
    "in_degrees = dict(G.in_degree())\n",
    "\n",
    "print(\"[2/4] Computing closeness and eigenvector centrality...\")\n",
    "closeness = nx.closeness_centrality(G)\n",
    "try:\n",
    "    eigenvector = nx.eigenvector_centrality(G, max_iter=100)\n",
    "except:\n",
    "    print(\"   Warning: Eigenvector centrality failed, using zeros\")\n",
    "    eigenvector = {node: 0 for node in G.nodes()}\n",
    "\n",
    "# HITS algorithm (Hub and Authority scores)\n",
    "print(\"[3/4] Computing HITS (hub/authority scores)...\")\n",
    "hits_h, hits_a = nx.hits(G, max_iter=100)\n",
    "\n",
    "# Additional structural features\n",
    "print(\"[4/4] Computing additional structural features...\")\n",
    "# Remove self-loop edges\n",
    "G.remove_edges_from(nx.selfloop_edges(G))\n",
    "core_number = nx.core_number(G)  # k-core decomposition\n",
    "triangles = nx.triangles(G.to_undirected())  # number of triangles\n",
    "\n",
    "# Average neighbor degree\n",
    "avg_neighbor_deg = nx.average_neighbor_degree(G)\n",
    "\n",
    "# Harmonic centrality (works better for disconnected graphs)\n",
    "print(\"   Computing harmonic centrality...\")\n",
    "harmonic_cent = nx.harmonic_centrality(G)\n",
    "\n",
    "# Compute eccentricity for connected nodes (faster alternative to betweenness)\n",
    "print(\"   Computing eccentricity...\")\n",
    "try:\n",
    "    # Only compute for nodes in the largest strongly connected component\n",
    "    largest_scc = max(nx.strongly_connected_components(G), key=len)\n",
    "    G_scc = G.subgraph(largest_scc)\n",
    "    eccentricity_scc = nx.eccentricity(G_scc)\n",
    "    eccentricity = {node: eccentricity_scc.get(node, 0) for node in G.nodes()}\n",
    "except:\n",
    "    eccentricity = {node: 0 for node in G.nodes()}\n",
    "\n",
    "print(\"\\nâœ“ All graph features computed!\\n\")\n",
    "\n",
    "# Build feature dataframe\n",
    "sender_features = []\n",
    "print(\"Extracting features for each sender...\")\n",
    "\n",
    "for sender, group in tqdm(df.groupby('sender'), desc=\"Processing senders\"):\n",
    "    if sender not in G:\n",
    "        continue\n",
    "    \n",
    "    out_deg = out_degrees.get(sender, 0)\n",
    "    if out_deg == 0:\n",
    "        continue\n",
    "    \n",
    "    in_deg = in_degrees.get(sender, 0)\n",
    "    \n",
    "    # Email statistics\n",
    "    total_sent = len(group)\n",
    "    spam_sent = group['label'].sum()\n",
    "    spam_ratio = spam_sent / total_sent\n",
    "    \n",
    "    # Reciprocity\n",
    "    receivers = list(G.successors(sender))\n",
    "    reciprocity = (\n",
    "        sum(1 for r in receivers if G.has_edge(r, sender)) / len(receivers)\n",
    "        if receivers else 0\n",
    "    )\n",
    "    \n",
    "    # Average weight of outgoing edges\n",
    "    avg_weight = (\n",
    "        np.mean([G[sender][r]['weight'] for r in receivers])\n",
    "        if receivers else 0\n",
    "    )\n",
    "    \n",
    "    # Max weight (strongest connection)\n",
    "    max_weight = (\n",
    "        max([G[sender][r]['weight'] for r in receivers])\n",
    "        if receivers else 0\n",
    "    )\n",
    "    \n",
    "    # Weight variance (consistency of connections)\n",
    "    weight_variance = (\n",
    "        np.var([G[sender][r]['weight'] for r in receivers])\n",
    "        if len(receivers) > 1 else 0\n",
    "    )\n",
    "    \n",
    "    # Ego network features\n",
    "    ego_graph = nx.ego_graph(G, sender, radius=1)\n",
    "    ego_density = nx.density(ego_graph) if ego_graph.number_of_nodes() > 1 else 0\n",
    "    ego_nodes = ego_graph.number_of_nodes() - 1  # exclude ego itself\n",
    "    ego_edges = ego_graph.number_of_edges()\n",
    "    \n",
    "    # Out/In degree ratio\n",
    "    in_out_ratio = in_deg / (out_deg + 1e-10)\n",
    "    \n",
    "    # Degree difference\n",
    "    degree_diff = out_deg - in_deg\n",
    "    \n",
    "    # Local clustering of neighbors\n",
    "    neighbors = list(G.successors(sender)) + list(G.predecessors(sender))\n",
    "    neighbor_clustering = (\n",
    "        np.mean([clustering.get(n, 0) for n in neighbors])\n",
    "        if neighbors else 0\n",
    "    )\n",
    "    \n",
    "    # Average PageRank of neighbors (do they connect to important people?)\n",
    "    neighbor_pagerank = (\n",
    "        np.mean([pagerank.get(n, 0) for n in neighbors])\n",
    "        if neighbors else 0\n",
    "    )\n",
    "    \n",
    "    # Receiver diversity\n",
    "    receiver_diversity = len(set(receivers)) / (out_deg + 1e-10)\n",
    "    \n",
    "    # Connection strength concentration (Gini coefficient of weights)\n",
    "    if len(receivers) > 1:\n",
    "        weights = sorted([G[sender][r]['weight'] for r in receivers])\n",
    "        n = len(weights)\n",
    "        index = np.arange(1, n + 1)\n",
    "        gini = (2 * np.sum(index * weights)) / (n * np.sum(weights)) - (n + 1) / n\n",
    "    else:\n",
    "        gini = 0\n",
    "    \n",
    "    # Unique receivers ratio\n",
    "    unique_receiver_ratio = len(set(receivers)) / total_sent if total_sent > 0 else 0\n",
    "    \n",
    "    # Incoming email statistics\n",
    "    predecessors = list(G.predecessors(sender))\n",
    "    num_senders_to_me = len(predecessors)\n",
    "    \n",
    "    # Mutual connections (both send to each other)\n",
    "    mutual_connections = sum(1 for r in receivers if G.has_edge(r, sender))\n",
    "    mutual_ratio = mutual_connections / out_deg if out_deg > 0 else 0\n",
    "    \n",
    "    sender_features.append({\n",
    "        # Basic info\n",
    "        'sender': sender,\n",
    "        'total_sent': total_sent,\n",
    "        'spam_ratio': spam_ratio,\n",
    "        'is_spammer': 1 if spam_ratio > 0.8 else 0,\n",
    "        \n",
    "        # Degree features\n",
    "        'out_degree': out_deg,\n",
    "        'in_degree': in_deg,\n",
    "        'total_degree': out_deg + in_deg,\n",
    "        'in_out_ratio': in_out_ratio,\n",
    "        'degree_diff': degree_diff,\n",
    "        \n",
    "        # Centrality features (FAST ONLY)\n",
    "        'pagerank': pagerank.get(sender, 0),\n",
    "        'closeness': closeness.get(sender, 0),\n",
    "        'eigenvector': eigenvector.get(sender, 0),\n",
    "        'harmonic_centrality': harmonic_cent.get(sender, 0),\n",
    "        'eccentricity': eccentricity.get(sender, 0),\n",
    "        'degree_centrality': out_deg / (G.number_of_nodes() - 1),\n",
    "        \n",
    "        # HITS scores\n",
    "        'hub_score': hits_h.get(sender, 0),\n",
    "        'authority_score': hits_a.get(sender, 0),\n",
    "        \n",
    "        # Clustering and community\n",
    "        'clustering': clustering.get(sender, 0),\n",
    "        'triangles': triangles.get(sender, 0),\n",
    "        'core_number': core_number.get(sender, 0),\n",
    "        'neighbor_clustering': neighbor_clustering,\n",
    "        'neighbor_pagerank': neighbor_pagerank,\n",
    "        \n",
    "        # Reciprocity and interaction\n",
    "        'reciprocity': reciprocity,\n",
    "        'mutual_connections': mutual_connections,\n",
    "        'mutual_ratio': mutual_ratio,\n",
    "        'num_senders_to_me': num_senders_to_me,\n",
    "        \n",
    "        # Weight features\n",
    "        'avg_weight': avg_weight,\n",
    "        'max_weight': max_weight,\n",
    "        'weight_variance': weight_variance,\n",
    "        'weight_gini': gini,\n",
    "        \n",
    "        # Diversity features\n",
    "        'avg_neighbor_degree': avg_neighbor_deg.get(sender, 0),\n",
    "        'receiver_diversity': receiver_diversity,\n",
    "        'unique_receiver_ratio': unique_receiver_ratio,\n",
    "        \n",
    "        # Ego network features\n",
    "        'ego_density': ego_density,\n",
    "        'ego_nodes': ego_nodes,\n",
    "        'ego_edges': ego_edges,\n",
    "    })\n",
    "\n",
    "features_df = pd.DataFrame(sender_features)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" FEATURE EXTRACTION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total features: {len(features_df.columns)}\")\n",
    "print(f\"Senders analyzed: {len(features_df):,}\")\n",
    "print(f\"Spammers: {features_df['is_spammer'].sum():,}\")\n",
    "print(f\"Legitimate: {(features_df['is_spammer'] == 0).sum():,}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" SAMPLE OF EXTRACTED FEATURES\")\n",
    "print(\"=\"*70)\n",
    "print(features_df.head())\n",
    "\n",
    "# ============================================================================\n",
    "# ENHANCED COMPARISON: SPAMMER vs LEGITIMATE\n",
    "# ============================================================================\n",
    "\n",
    "comparison_features = [\n",
    "    # Degree\n",
    "    'out_degree', 'in_degree', 'in_out_ratio', 'degree_diff',\n",
    "    # Centrality\n",
    "    'pagerank', 'closeness', 'eigenvector', 'harmonic_centrality', 'eccentricity',\n",
    "    'hub_score', 'authority_score',\n",
    "    # Community\n",
    "    'clustering', 'triangles', 'core_number', 'neighbor_clustering', 'neighbor_pagerank',\n",
    "    # Reciprocity\n",
    "    'reciprocity', 'mutual_ratio', 'num_senders_to_me',\n",
    "    # Weights\n",
    "    'avg_weight', 'max_weight', 'weight_variance', 'weight_gini',\n",
    "    # Diversity\n",
    "    'receiver_diversity', 'unique_receiver_ratio', 'avg_neighbor_degree',\n",
    "    # Ego\n",
    "    'ego_density', 'ego_nodes'\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for feature in comparison_features:\n",
    "    spam_vals = features_df[features_df['is_spammer'] == 1][feature]\n",
    "    legit_vals = features_df[features_df['is_spammer'] == 0][feature]\n",
    "    \n",
    "    spam_mean = spam_vals.mean()\n",
    "    legit_mean = legit_vals.mean()\n",
    "    spam_med = spam_vals.median()\n",
    "    legit_med = legit_vals.median()\n",
    "    \n",
    "    ratio = spam_mean / legit_mean if legit_mean > 0 else float('inf')\n",
    "    \n",
    "    rows.append([\n",
    "        feature,\n",
    "        round(spam_mean, 6),\n",
    "        round(legit_mean, 6),\n",
    "        round(spam_med, 6),\n",
    "        round(legit_med, 6),\n",
    "        round(ratio, 3),\n",
    "        \"Spam higher\" if ratio > 1 else \"Legit higher\"\n",
    "    ])\n",
    "\n",
    "compare_table = pd.DataFrame(rows, columns=[\n",
    "    \"Feature\", \"Spam Mean\", \"Legit Mean\", \"Spam Median\", \"Legit Median\", \n",
    "    \"Ratio\", \"Interpretation\"\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" COMPREHENSIVE FEATURE COMPARISON: SPAMMER vs LEGITIMATE\")\n",
    "print(\"=\"*70)\n",
    "print(compare_table.to_string(index=False))\n",
    "\n",
    "# Highlight top discriminative features\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" TOP FEATURES THAT DISTINGUISH SPAMMERS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "compare_table['abs_diff'] = abs(compare_table['Ratio'] - 1.0)\n",
    "top_features = compare_table.nlargest(10, 'abs_diff')\n",
    "\n",
    "print(\"\\nTop 10 most discriminative features:\")\n",
    "print(top_features[['Feature', 'Spam Mean', 'Legit Mean', 'Ratio']].to_string(index=False))\n",
    "\n",
    "# Key insights\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" KEY INSIGHTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "spam = features_df[features_df['is_spammer'] == 1]\n",
    "legit = features_df[features_df['is_spammer'] == 0]\n",
    "\n",
    "print(\"\\nðŸŽ¯ CENTRALITY DIFFERENCES:\")\n",
    "print(f\"   PageRank:     Spam={spam['pagerank'].mean():.6f} vs Legit={legit['pagerank'].mean():.6f}\")\n",
    "print(f\"   Closeness:    Spam={spam['closeness'].mean():.6f} vs Legit={legit['closeness'].mean():.6f}\")\n",
    "print(f\"   Eigenvector:  Spam={spam['eigenvector'].mean():.6f} vs Legit={legit['eigenvector'].mean():.6f}\")\n",
    "print(f\"   Hub score:    Spam={spam['hub_score'].mean():.6f} vs Legit={legit['hub_score'].mean():.6f}\")\n",
    "print(f\"   Authority:    Spam={spam['authority_score'].mean():.6f} vs Legit={legit['authority_score'].mean():.6f}\")\n",
    "\n",
    "print(\"\\nðŸ“Š STRUCTURAL DIFFERENCES:\")\n",
    "print(f\"   Core number:  Spam={spam['core_number'].mean():.2f} vs Legit={legit['core_number'].mean():.2f}\")\n",
    "print(f\"   Triangles:    Spam={spam['triangles'].mean():.2f} vs Legit={legit['triangles'].mean():.2f}\")\n",
    "print(f\"   Ego density:  Spam={spam['ego_density'].mean():.4f} vs Legit={legit['ego_density'].mean():.4f}\")\n",
    "print(f\"   Clustering:   Spam={spam['clustering'].mean():.4f} vs Legit={legit['clustering'].mean():.4f}\")\n",
    "\n",
    "print(\"\\nðŸ”— INTERACTION PATTERNS:\")\n",
    "print(f\"   In/Out ratio:     Spam={spam['in_out_ratio'].mean():.4f} vs Legit={legit['in_out_ratio'].mean():.4f}\")\n",
    "print(f\"   Reciprocity:      Spam={spam['reciprocity'].mean():.4f} vs Legit={legit['reciprocity'].mean():.4f}\")\n",
    "print(f\"   Mutual ratio:     Spam={spam['mutual_ratio'].mean():.4f} vs Legit={legit['mutual_ratio'].mean():.4f}\")\n",
    "print(f\"   Receiver div:     Spam={spam['receiver_diversity'].mean():.4f} vs Legit={legit['receiver_diversity'].mean():.4f}\")\n",
    "print(f\"   Weight Gini:      Spam={spam['weight_gini'].mean():.4f} vs Legit={legit['weight_gini'].mean():.4f}\")\n",
    "print(f\"   Neighbor PR:      Spam={spam['neighbor_pagerank'].mean():.6f} vs Legit={legit['neighbor_pagerank'].mean():.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
